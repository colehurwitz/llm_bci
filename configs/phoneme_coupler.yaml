# Project to llama hidden space
input_size: 41      # must be equal to size of phonemes vocabulary (including SIL and BLANK)
inter_size: 2048    # size of the intermediate layer in the adapter MLP
act: tanh           # activation function in the adapter MLP
bias: False

loss_reduction: sum


