trlx.train: 
-> model_path can be path to pretrained peft adapter. 
Also it is important (i think) to remember to set :
config.model.model_extra_configs["peft_from_pretrained_kwargs"] = {"is_trainable": True}
Maybe pass the model loaded directly. And use the post_init method in from_pretrained

utils.pipeline.offline_pipeline.PromptPipeline: Here it creates from the text prompts the inputs to the model. 
Changing prompts for input embeds and plugging them at this point would be useful. I should create EmbedPipeline
mirroring PromptPipeline. If prompts is a dict, the keys different from "input_embeds" in this case, would be passed to the reward_fn eventually

trainer.accelerate_ppo_trainer
-> line285: we want to use "input_embeds" for generation, possibly "attention_mask"
-> line286-300: prompt_tensors will be input_embeds, check that everything makes sense
-> line 301: the kwargs we want to remove are "input_embeds"
-> line 303: it decodes the prompts to text, so probably we also want to keep the prompt "input_ids" in the Pipeline
-> line 415 onwards: ensure that the hydra model receives input_embeds
-> line127-onwards in "loss" also make forward pass with input_embeds
trainer.accelerate_base_trainer:
-> line383: generate with "input_embeds"
-> in the follwing lines, prompt.input_ids is used, we could keep that




