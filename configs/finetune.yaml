seed: 1
savestring: test
data_file: mix_data.pth
log_to_wandb: false
wandb_project: phonemes_ft

dirs: include:configs/sc_dirs.yaml

freeze_llm: false
debug: false

# prompt: "You are an expert decoding words from speech recordings. This is a sequence of phonemes \
#         that correspond to a sentence. They have some noise in it, so you \
#           will have to take into account the rest of the sentence to decode each word so that it makes \
#           sense as a whole. The phonemes are: %% The sentence is:"

prompt: "phonemes: %% sentence:"

trainer:
  save_data: true
  num_epochs: 1
  save_every: 1000         # steps to save
  eval_every: 1000         # steps to evaluate
  train_len: -1           # -1 to use whole set
  test_len: 256           # -1 to use whole set
  train_batch_size: 1
  test_batch_size: 1

optimizer:
  gradient_accumulation_steps: 16
  lr: 1.e-4
  wd: 0.01
  eps: 1.e-8
  warmup_pct: 0.0
  gamma: 0.99
  scheduler: step

lora:
  r: 1
  alpha: 32
  dropout: 0.2
  target_modules: ["q_proj","v_proj"] #,"k_proj","o_proj"]

generation:
  max_new_tokens: 20
  do_sample: False
  # top_p: null
  # top_k: 50
  temperature: 1.0
  # repetition_penalty: 1.0
  # length_penalty: 1.0
  # min_length: null
  # num_beams: 1
  # num_beam_groups: 1
  # no_repeat_ngram_size: 2
  # renormalize_logits: true
  low_memory: true
  # diversity_penalty: 1.2
  num_return_sequences: 1
  # output_score: false
  # return_dict_in_generate: false

noise:
  norm: identity       #softmax/logsoftmax/identity
  temperature: 1
  gauss_mean: 0.0
  gauss_sd: 0.5
  max_spikes: 3
  p_spike: 0.6
  spike_scale: 3.0
  # p_trunc: 0.4
  # max_trunc: 0.9
  # min_trunc: 0.4

mask:
  ratio: 0.0
  max_span: 5

coupler: include:configs/phoneme_coupler.yaml
