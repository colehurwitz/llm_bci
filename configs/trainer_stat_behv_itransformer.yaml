seed: 1

savestring: test
wandb_project: test
log_to_wandb: false

verbosity: 0

# Logging directories
dirs:
  checkpoint_dir: /home/gridsan/dbeneto/TFG/BCI/pt_checkpoints  # save model state dicts (todo optimizer states)
  log_dir: /home/gridsan/dbeneto/TFG/BCI/pt_logs  # save tensorboard logs


# Training configuration
training:
  num_epochs: 100
  train_batch_size: 16
  test_batch_size: 16   
  shuffle_test_dataloader: false      # Shuffle test dataloader between epochs
  drop_last_test_dataloader: true     # Drop last batch of test dataloader to ensure same batch size
  drop_last_train_dataloader: true    # Drop last batch to ensure same batch size

  save_every: 100 # Save checkpoint
  eval_every: 100  # Eval model



model: include:configs/itransformer.yaml

data:
  dataset_class: decoding

  hf_dataset_name: null
  json_dataset_name: null
  
  train_name: train   # name of the train split in the raw datasete
  test_name: test     # name of the test split in the raw datasete
  train_len: null     # used length of the train dataset. null to use all
  test_len: null      # used length of the test dataset. null to use all

  data_load: ibl # ibl/file/speechbci
  data_dir: /home/gridsan/dbeneto/MAML-Soljacic_shared/BCI/data

  data_file: null

  eid: 671c7ea7-6726-4fbe-adeb-f89c2c8e489b/stimulus_20ms
  test_size: 0.15
  static_behaviours: ["block","choice","reward"]
  dynamic_behaviours: []
  norm_behaviours: false
  seed: 42

  zscore: false
  features: ["tx1"]
  date_idxs: null
  
method:

  model_kwargs:
    method_name: stat_behaviour

    loss: xent # xent/mse
    n_labels: 2

  dataset_kwargs: 
    targets_name: choice


  dataloader_kwargs:
    pad_dict:
      spikes:
        dim: 0
        side: left
        value: 0
        truncate: null
        min_length: null
      spikes_mask:
        dim: 0
        side: left
        value: 0
        truncate: null
        min_length: null
      spikes_timestamp:
        dim: 0
        side: left
        value: 0
        truncate: null
        min_length: null
      spikes_spacestamp:
        dim: 0
        side: left
        value: 0
        truncate: null
        min_length: null

  metric_kwargs: {}

optimizer:
  gradient_accumulation_steps: 1
  lr: 1.e-4
  wd: 0.01
  eps: 1.e-8
  warmup_pct: 0.15 # cosine/linear
  gamma: 0.95     # step
  div_factor: 25  # cosine
  scheduler: cosine # step/cosine/linear
